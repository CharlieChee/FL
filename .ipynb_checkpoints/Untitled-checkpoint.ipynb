{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c898701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import copy\n",
    "\n",
    "import random\n",
    "# 定义多层感知机（MLP）模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def federated_learning(train_loader, test_loader, input_size, hidden_size, num_classes, learning_rate,\n",
    "                       batch_size, communication_rounds, local_epochs):\n",
    "    # 初始化模型和优化器\n",
    "    global_model = MLP(input_size, hidden_size, num_classes)\n",
    "    global_optimizer = optim.SGD(global_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for round in range(communication_rounds):\n",
    "        print(f\"Communication Round {round+1}/{communication_rounds}\")\n",
    "        local_models = []\n",
    "\n",
    "        # 在每个client上训练模型\n",
    "        for images, labels in train_loader:\n",
    "            local_model = copy.deepcopy(global_model)\n",
    "            local_optimizer = optim.SGD(local_model.parameters(), lr=learning_rate)\n",
    "\n",
    "            for epoch in range(local_epochs):\n",
    "                local_optimizer.zero_grad()\n",
    "                outputs = local_model(images.view(-1, input_size))\n",
    "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                loss.backward()\n",
    "                local_optimizer.step()\n",
    "\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        # 聚合模型参数（使用FedAvg）\n",
    "        avg_weights = []\n",
    "        local_state_dicts = [local_model.state_dict() for local_model in local_models]\n",
    "\n",
    "        for layer in global_model.state_dict().keys():\n",
    "            layer_weights = torch.stack([local_state_dict[layer] for local_state_dict in local_state_dicts])\n",
    "            avg_weights.append(torch.mean(layer_weights, dim=0))\n",
    "\n",
    "        global_model.load_state_dict(dict(zip(global_model.state_dict().keys(), avg_weights)))\n",
    "\n",
    "        print(\"Global model updated\")\n",
    "\n",
    "    # 在联邦学习结束后，计算并输出训练准确率和测试准确率\n",
    "    with torch.no_grad():\n",
    "        global_model.eval()\n",
    "\n",
    "        # 计算训练准确率\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, labels in train_loader:\n",
    "            outputs = global_model(images.view(-1, input_size))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        # 计算测试准确率\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = global_model(images.view(-1, input_size))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "\n",
    "        return train_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b683822",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 151\u001b[0m\n\u001b[1;32m    147\u001b[0m global_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(cnn_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# 调用 federated_learning 函数\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# 调用 federated_learning 函数\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m federated_learning(\u001b[43mtrain_loader\u001b[49m, test_loader, input_size, hidden_size,\n\u001b[1;32m    152\u001b[0m                                                    num_classes, learning_rate, batch_size,\n\u001b[1;32m    153\u001b[0m                                                    communication_rounds, local_epochs)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import numpy as np\n",
    "\n",
    "# 全局变量，用于存储生成的邻接矩阵\n",
    "adjacency_matrix = None\n",
    "deleted_nodes = None\n",
    "global adjacency_matrix_deleted\n",
    "num_nodes = None\n",
    "deleted_nodes = set()\n",
    "\n",
    "def generate_original_matrix():\n",
    "    global adjacency_matrix  # 声明为全局变量\n",
    "    global num_nodes\n",
    "    num_nodes = int(num_nodes_entry.get())\n",
    "    distribution = distribution_combobox.get()\n",
    "    \n",
    "    if distribution == \"Poisson\":\n",
    "        average_degree = 4\n",
    "        degree_sequence = np.random.poisson(average_degree, num_nodes)\n",
    "    else:\n",
    "        exponent = 2.5\n",
    "        degree_sequence = np.random.zipf(exponent, num_nodes)\n",
    "        while sum(degree_sequence) % 2 != 0:\n",
    "            degree_sequence[np.random.randint(num_nodes)] += 1\n",
    "    \n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        neighbors = np.random.choice(num_nodes, size=degree_sequence[i], replace=False)\n",
    "        adjacency_matrix[i, neighbors] = 1\n",
    "        adjacency_matrix[neighbors, i] = 1  # 对称的部分\n",
    "    \n",
    "    np.fill_diagonal(adjacency_matrix, 0)\n",
    "    \n",
    "    result_text.config(state=\"normal\")\n",
    "    result_text.delete(\"1.0\", tk.END)\n",
    "    result_text.insert(tk.END, \"Original Adjacency Matrix:\\n\")\n",
    "    result_text.insert(tk.END, str(adjacency_matrix))\n",
    "    result_text.config(state=\"disabled\")\n",
    "\n",
    "def generate_remaining_matrix():\n",
    "    global adjacency_matrix  # 声明为全局变量\n",
    "    global deleted_nodes\n",
    "    global adjacency_matrix_deleted\n",
    "    \n",
    "    num_deleted_nodes = int(num_deleted_nodes_entry.get())\n",
    "    adjacency_matrix_deleted = adjacency_matrix.copy()\n",
    "    \n",
    "    deleted_nodes.clear()  # 清空已删除节点集合\n",
    "    \n",
    "    while len(deleted_nodes) < num_deleted_nodes:\n",
    "        node_to_delete = np.random.randint(adjacency_matrix.shape[0])\n",
    "        if node_to_delete not in deleted_nodes:  # 检查节点是否已经在删除列表中\n",
    "            deleted_nodes.add(node_to_delete)\n",
    "            adjacency_matrix_deleted[node_to_delete, :] = 0\n",
    "            adjacency_matrix_deleted[:, node_to_delete] = 0\n",
    "    \n",
    "    result_text.config(state=\"normal\")\n",
    "    result_text.delete(\"1.0\", tk.END)  # 清空文本框内容\n",
    "    result_text.insert(tk.END, \"Deleted Nodes:\\n\")\n",
    "    result_text.insert(tk.END, str(list(deleted_nodes)))  # 打印删除的节点\n",
    "    \n",
    "    result_text.insert(tk.END, \"\\nRemaining Nodes Adjacency Matrix:\\n\")\n",
    "    result_text.insert(tk.END, str(adjacency_matrix_deleted))\n",
    "    result_text.config(state=\"disabled\")\n",
    "\n",
    "\n",
    "\n",
    "# 创建窗口\n",
    "window = tk.Tk()\n",
    "window.title(\"Graph Generator\")\n",
    "window_width = 800\n",
    "window_height = 600\n",
    "window.geometry(f\"{window_width}x{window_height}\")\n",
    "\n",
    "# 参数框\n",
    "num_nodes_label = tk.Label(window, text=\"Number of Nodes:\")\n",
    "num_nodes_label.pack()\n",
    "num_nodes_entry = tk.Entry(window)\n",
    "num_nodes_entry.insert(0, \"10\")\n",
    "num_nodes_entry.pack()\n",
    "\n",
    "distribution_label = tk.Label(window, text=\"Distribution:\")\n",
    "distribution_label.pack()\n",
    "distribution_combobox = ttk.Combobox(window, values=[\"Poisson\", \"Power Law\"])\n",
    "distribution_combobox.set(\"Poisson\")\n",
    "distribution_combobox.pack()\n",
    "\n",
    "num_deleted_nodes_label = tk.Label(window, text=\"Number of Deleted Nodes:\")\n",
    "num_deleted_nodes_label.pack()\n",
    "num_deleted_nodes_entry = tk.Entry(window)\n",
    "num_deleted_nodes_entry.insert(0, \"5\")\n",
    "num_deleted_nodes_entry.pack()\n",
    "\n",
    "generate_original_button = tk.Button(window, text=\"Generate Original Adjacency Matrix\", command=generate_original_matrix)\n",
    "generate_original_button.pack()\n",
    "\n",
    "generate_remaining_button = tk.Button(window, text=\"Generate Remaining Adjacency Matrix\", command=generate_remaining_matrix)\n",
    "generate_remaining_button.pack()\n",
    "\n",
    "result_text = tk.Text(window, height=50, width=70)\n",
    "result_text.config(state=\"disabled\")\n",
    "result_text.pack()\n",
    "\n",
    "window.mainloop()\n",
    "###############################################\n",
    "\n",
    "# 超参数\n",
    "input_size = 28 * 28  # MNIST图片大小为28x28\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 16\n",
    "communication_rounds = 1\n",
    "local_epochs = 2\n",
    "num_clients = int(num_nodes)\n",
    "\n",
    "# 加载MNIST数据集\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "\n",
    "client_data_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(client_data_indices)\n",
    "client_data_per_client = len(client_data_indices) // num_clients\n",
    "# 从10个客户端中选择m个客户端进行联邦学习\n",
    "\n",
    "client_selected_list = list((set(range(int(num_nodes))))-set(deleted_nodes))\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loaders_selected = []\n",
    "for client_idx in client_selected_list:\n",
    "    client_start_idx = client_idx * client_data_per_client\n",
    "    client_end_idx = (client_idx + 1) * client_data_per_client\n",
    "    selected_indices = client_data_indices[client_start_idx:client_end_idx]\n",
    "    \n",
    "    train_loader_selected = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                                        sampler=torch.utils.data.SubsetRandomSampler(selected_indices))\n",
    "    train_loaders_selected.append(train_loader_selected)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 初始化模型和优化器\n",
    "cnn_model = CNN(num_classes)  # 使用你定义的CNN模型\n",
    "global_optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 调用 federated_learning 函数\n",
    "train_accuracy, test_accuracy = federated_learning(train_loader_selected, test_loader, input_size, hidden_size,\n",
    "                                                   num_classes, learning_rate, batch_size,\n",
    "                                                   communication_rounds, local_epochs)\n",
    "\n",
    "print(f\"Final Train Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af984f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication Round 1/2\n",
      "Global model updated\n",
      "Communication Round 2/2\n",
      "Global model updated\n",
      "Final Train Accuracy: 15.60%\n",
      "Final Test Accuracy: 16.43%\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
